{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification demo including training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##Import libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0204 13:57:11.572608  3056 deprecation_wrapper.py:119] From C:\\Users\\Administrator\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0204 13:57:18.734918  3056 deprecation_wrapper.py:119] From C:\\Users\\Administrator\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0204 13:57:19.145839  3056 deprecation_wrapper.py:119] From C:\\Users\\Administrator\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0204 13:57:19.408908  3056 deprecation_wrapper.py:119] From C:\\Users\\Administrator\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Convolution(64 feature detector of dimension 3 by 3), input shape 3 layer for color image)\n",
    "classifier.add(Conv2D(64,(3,3),input_shape = (64,64,3), activation = 'relu'))\n",
    "## MaxPooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "## Add another layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "## Add another layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fully connected ANN, Hidden ANN and output layer\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0204 13:57:37.707132  3056 deprecation_wrapper.py:119] From C:\\Users\\Administrator\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0204 13:57:37.751109  3056 deprecation_wrapper.py:119] From C:\\Users\\Administrator\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0204 13:57:37.788769  3056 deprecation.py:323] From C:\\Users\\Administrator\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "## Compliling\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 370,817\n",
      "Trainable params: 370,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data importing and transforming and scaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data importing and transforming and scaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling test data\n",
    "##no  data augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Importing training data\n",
    "train_set = train_datagen.flow_from_directory('dataset2\\\\training_set2',\n",
    "                                               target_size=(64, 64),\n",
    "                                               class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with tumor': 0, 'without tumor': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with tumor': 0, 'without tumor': 1}\n"
     ]
    }
   ],
   "source": [
    "#which is cat which is dog?\n",
    "label_map = (train_set.class_indices)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Importng test data\n",
    "test_set = test_datagen.flow_from_directory('dataset2\\\\test_set2',\n",
    "                                            target_size=(64, 64),\n",
    "                                            \n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 8s 791ms/step - loss: 0.1251 - acc: 0.9348 - val_loss: 0.0966 - val_acc: 0.9512\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 7s 747ms/step - loss: 0.1240 - acc: 0.9454 - val_loss: 0.0971 - val_acc: 0.9512\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 8s 761ms/step - loss: 0.0819 - acc: 0.9494 - val_loss: 0.0794 - val_acc: 0.9512\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 8s 754ms/step - loss: 0.1106 - acc: 0.9487 - val_loss: 0.1809 - val_acc: 0.9268\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 8s 751ms/step - loss: 0.1333 - acc: 0.9388 - val_loss: 0.1247 - val_acc: 0.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x189579f9978>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting model to images\n",
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        epochs=5,\n",
    "        validation_data=test_set,\n",
    "        steps_per_epoch=10,\n",
    "        validation_steps=38\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fitting model to images\n",
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=50,\n",
    "        epochs=5,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction of single new data\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image= image.load_img('dataset2\\\\single_prediction\\\\IMG-0004-00001.jpg'\n",
    "                           ,target_size =(64,64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x18958ECC470>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert image to array\n",
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For single prediction change the dimension . \n",
    "\n",
    "test_image=test_image.reshape(1,64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class label of dog and cat\n",
    "\n",
    "if result == 1:\n",
    "    prediction = 'without tumor'\n",
    "else:\n",
    "    prediction = 'with tumor'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with tumor'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#steps_per_epoch=50\n",
    "#Save mode\n",
    "#serialize model to JSON\n",
    "model1_json=classifier.to_json()\n",
    "with open(\"model1.json\",\"w\") as json_file:\n",
    "    json_file.write(model1_json)\n",
    "# serialize weights to HDFS\n",
    "classifier.save_weights(\"model1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
